# LLM Perfect Match

## â” Sommaire

- [â” Structure du projet](#-structure-du-projet)
- [â” Installation & Lancement](#-installation--lancement)
- [â” FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [â” Exemples de rÃ©sultat](#-exemples-de-rÃ©sultat)
- [â” CritÃ¨res dâ€™Ã©valuation](#-critÃ¨res-dÃ©valuation)
- [â” Indicateurs de performance](#-indicateurs-de-performance)
- [â” Licence](#-licence)
- [â” Auteurs](#-auteurs)

---

## ğŸ—‚ï¸ Structure du projet

Ce projet construit une interface en **Django** qui permet de faire le *matching* parfait entre questions utilisateurs et rÃ©ponses adaptÃ©es gÃ©nÃ©rÃ©es par un modÃ¨le LLM (GPT-like).

Dossier `Projet_LLM` (branche `django`) contient :

- **manage.py** : point dâ€™entrÃ©e Django pour lancer le serveur, migrations, etc.
- **llm\_pm/** : application Django principale
  - `views.py` : logique des vues pour envoyer la question et afficher la rÃ©ponse.
  - `models.py` : dÃ©finit les modÃ¨les de donnÃ©es (ex : historiques de requÃªtes).
  - `forms.py` : gÃ¨re la saisie des questions via un formulaire web.
  - `urls.py` : route les URLs (`/ask`, `/history`, etc.).
  - `templates/` : pages HTML (`ask.html`, `results.html`, `history.html`).
  - `static/` : ressources statiques (CSS, JS, images).
  - `llm_utils.py` : wrapper pour appeler lâ€™API LLM (ex : OpenAI, Hugging Face).
  - `matching.py` : algorithme pour trouver la rÃ©ponse la plus pertinente parmi les suggestions.
- **requirements.txt** : dÃ©pendances Python (`Django`, `requests`, `transformers`, etc.).
- **images/** : logos et captures dâ€™Ã©cran pour le README.

---

## ğŸš€ Installation & Lancement

1. Cloner le dÃ©pÃ´t :

   ```bash
   git clone https://github.com/Sami-Kbdn/DEV__IA--Projet_LLM.git
   cd DEV__IA--Projet_LLM
   git checkout django
   ```

2. CrÃ©er un environnement virtuel et installer les dÃ©pendances :

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

3. Configurer les variables dâ€™environnement (ex. `OPENAI_API_KEY`) :

   ```bash
   export OPENAI_API_KEY="votre_clef_api"
   ```

4. Appliquer les migrations, puis lancer le serveur :

   ```bash
   python manage.py migrate
   python manage.py runserver
   ```

5. Ouvrir lâ€™application dans votre navigateur Ã  lâ€™adresse :

   ```
   http://127.0.0.1:8000/ask
   ```

---

## âš™ï¸ FonctionnalitÃ©s

- **Poser une question** via un formulaire web.
- **Appel Ã  un LLM** (OpenAI/GPT, modÃ¨le Hugging Face, â€¦).
- **Matching intelligent** :
  - GÃ©nÃ©ration de plusieurs rÃ©ponses candidates,
  - Score de similaritÃ© (cosine, embeddingsâ€¦),
  - SÃ©lection de la rÃ©ponse la plus pertinente.
- **Historique des requÃªtes** avec affichage des questions + rÃ©ponses.
- **Interface propre et responsive** (HTML + CSS minimalistes).

---

## ğŸ–¼ï¸ Exemples de rÃ©sultat

*Interface montrant la question posÃ©e, la rÃ©ponse la mieux ajustÃ©e et lâ€™historique des Ã©changes*

---

## ğŸ“Œ CritÃ¨res dâ€™Ã©valuation

- **FonctionnalitÃ©** : fiabilitÃ© de lâ€™appel au LLM & pertinence du matching.
- **QualitÃ© du code** : lisibilitÃ©, modularitÃ©, commentaires.
- **UX/UI** : ergonomie du formulaire & de la page historique.
- **Workflow Git** : commits explicites, utilisation des branches.

---

## ğŸ“Š Indicateurs de performance

- **Taux de pertinence** : proportion de rÃ©ponses jugÃ©es Â«â€¯correctesâ€¯Â» ou Â«â€¯trÃ¨s pertinentesâ€¯Â» lors de tests utilisateurs.
- **Temps de rÃ©ponse** : latence moyenne (requÃªte â†’ rÃ©ponse affichÃ©e).
- **QualitÃ© du code** : outils comme `flake8`, couverture test (sâ€™il y a des tests).
- **ExpÃ©rience utilisateur** : retours sur lâ€™ergonomie, fluiditÃ© de navigation.

---

## ğŸ“ Licence

Ce projet est publiÃ© sous la licence **MIT**. Voir le fichier [LICENSE](LICENSE).

---

## ğŸ‘¨â€ğŸ’» Auteurs

**Sami Kbdn**\
&#x20;&#x20;

---

**Contact** : Sami Kbdn â€“ [[ton\_email@example.com](mailto\:ton_email@example.com)] *(ajuster si besoin)*

